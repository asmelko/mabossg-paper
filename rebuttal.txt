- Extend literature in the intro (R1 Q1)
- More detailed background 
-- Add a new background subsection describing CPU impl (R1 Q2,3,7)
-- Elaborate more on MaBoSS output (perhaps a new subsection with plotted outputs) (R1 Q4,7 R2 Q1)
-- Revise the algorithm (R1 Q5,6)
- Revise GPU stuff (R1 Q8,10,11,13 R2 Q2,3.1,3.3,3.5)
- Revise MPI stuff (R2 Q3.2,3.4)
- in Results add a table with models we used ? (R1 Q9)
- explain the MPI outlier (remeasure?) (R1 Q12) 
- minor stuff (rest)

First of all, we would like to thank the reviewers for their consideration of our paper and detailed remarks. We have addressed them in our paper revision. The individual answers are in the following. Minor remarks that were simply fixed in the paper and required no additional comments are omitted.

Reviewer #1:

Q: How is the parallelization for GPUs actually done? In the section MaBoSS.GPU, it is described, why there was no parallelization over the Boolean functions, but not about the rest. In the MPI section, it states, that each thread is assigned to compute a single trajectory at once. I would assume that this is also true for the GPU implementation, this should, however, be made clear.
A: You are right, we included this piece of information in the last paragraph of Simulation section.

Q: The legend in the figures needs to be more specific to be able to interpret the figures better: e.g. how many synthetic models? (are the 19 points the respective models?)
A: Yes, the x-axis shows multiple synthetic models of various sizes. We added this to Figure 2.

Q: In Figure1, the High-End NVIDIA TESLA is either slower or as fast as the consumer grade laptop GPU. Is this purely due to the compilation time (as Figure 2 would suggest, that it makes a difference)? 
A: You are right. You can see for yourself by comparing gpu_out_real.csv and gpu_out_real_a100.csv files in the artifact. We are unsure why the compilation takes longer for high-end GPU than for laptop GPU, after all, it is a proprietary piece of software. Perhaps the loading of shared libraries takes a different amount of time for the operating systems... We added a note in the Performance of MaBoSS.GPU section.

Q: There is no demonstration of how a user would actually deal with the code - especially since the GPU version is based on a hard-coded implementation of the rules. A demonstrative example would help to get an idea, how a user would actually get started, and how deep he needs to dig into the code - especially for a biological audience, accessability of such tools is an important point
A: Respectfully, it is not true that the GPU version is based on any hard-coded implementation. The compilation of the rules happens during the runtime without any user intervention. We included this note in the second paragraph of the Simulation section.

Q: It is stated that synthetic models with up to 1000 nodes were created. The synthetic models themselves are available, however, the description of the chosen models is also important to be mentioned in the paper: I would suggest a table that lists the most important features of the different models (size, nodes, formula sizes, how many different models were actually taken into account, ..) that were created (this table can also include the characteristics of the 3 real-world models to put in perspective). 
A: We included the proposed table in Results section and extended the first paragraph in the Benchmarking Methodology to describe the table fields.

Q: The statistics are described, but how would a user interpret them/make use of them for themselves? What is this shared associative structure that the model is updating? Maybe a diagram would be helpful for visualization?
A: We added a new section Statistics output and visualization, which includes how the statistics output is represented in the code and how a user can interpret and visualize it.

Q: How does the code actually deal with circular steady states?
A: If a model contains circular steady states, simulated trajectories that would indefinitely transition over circular states will eventually reach the maximum time and their simulation stops. Their statistics are further computed without any change. The original paper (Stoll et al.) discusses the ways how to detect circular steady states from the computed statistics, but we think that describing these methods is out of the scope of this paper. Therefore, we included general information about circular steady states in Statistics output and visualization section and referenced the original paper for the reader who wants to know more detailed information. 

Q: There needs to be a description about the original code. Most importantly, it is always referred to, as the CPU version. This suggests, that we are talking about a purely sequential code. In the Methodology, however, it is described to be run on a full 32-core node, which implies already some basic parallelization. This should be made clear from the beginning.
A: Indeed, the implementation of the "CPU version" was early on parallelized to work on multiple cores, using POSIX threads. We added a new subsection to the background section (MaBoSS CPU Implementation) to describe this implementation.

Q: The Boolean signaling modeling paragraph needs to be extended in more details: To me it is not clear, why e.g., the transition rates should be in [0, inf) and not [0,1], since we are talking about probabilities. The concept of asynchronous updating should be made a bit clearer as well. Furthermore, it is often referred to the evaluation of the Boolean formulas as the most expensive computational part. It would help to get an idea, how such a formula would look like, and how they are implemented, to give the reader context about this problem. Furthermore, the word "node" is used quite often in the paper, so it should be made clear, what this refers to exactly.
A: We extended the background section with all your comments. Regarding the node, [0, inf) transition rates and asynchronous updates, we added explanations to the first paragraphs of sections 2.1 and 2.2. In order to add an example of Boolean formula, we explained it in more detail by defining its binary function, which determines the transition rate using a simple rule in equation 5. Having the binary function, we presented its simple example in equation 4. The way how the boolean formulas are implemented in the code is described in the first paragraph of section 3.1, simply referring to it as a recursive traversal of an expression tree. 

Q: Algorithm 1 should be made clearer: how are transition rates computed? What does the bit-flip mean? delta t is computed using a "u" - where does that come from?
A: Transition rates are computed by evaluating boolean formulas of each node, as is written on line 2 of Algorithm 1. To make it clearer, we modified the second paragraph of section 2.2, where we explicitly state, that the output of boolean logic is the transition rates. Regarding "u", the Gillespie algorithm uses 2 random numbers (r,u) drawn from the uniform distribution to randomly select the transition node and the transition time. We added comments to the algorithm and added a line referencing that the algorithm follows the Gillespie algorithm.

Q: Please ellaborate more on the last point in Figure 5, that seems to be an outlier. Which synthetic model is this? Is it also found in the earlier figures? 
A: Firstly, we included additional information about the synthetic model in the figure caption. Secondly, we analyzed the datapoint and it is the same case as in the previous MPI figure - the problem is distributed into so many small tasks that the actual cost of MPI communication becomes the bottleneck. We are sorry that we did not include this information in the first version - initially the figure was plotted in a different way which did not show this drastic speedup difference, after replotting the datapoint went unnoticed.

Reviewer #2:

Q: Figure 3: The x-axis states “Nodes count (log−scale)”, however, it appears to have a linear scale. The linear relationships claimed in the statement “We observed that the compilation time is linearly dependent on the number of nodes and formula lengths (measured in the number of occurring nodes).” is not clear from the provided figures, and should be clarified or, for example provide Figure 3 with a linear-linear or log-log scale.
A: Thanks for pointing out the wrong scale in the plot, it is a linear scale. Regarding the linear dependency, it can not be seen from Fig 3 since it shows compilation time percentages rather than the absolute values. Therefore, plotting a linear-linear scale would not show any linear dependency. Nevertheless, the stated linear dependency is indeed there and we observed it from the plots which we did not include in the paper. The general idea why it holds is that increasing the number of nodes by a value of x adds O(x) new lines to a source file which needs to be compiled. We included this explanation in the paper.

Q: I was able to successfully compile MaBoSS with MPI enabled, however I was not able to compile MaBoSS.GPU in a Linux environment.
A: Thanks, compiling with the newest CUDA version revealed a bug in the Thrust dependency. We committed a workaround.

Q: The MaBoSS.GPU README could do with a link to documentation.
A: We added a new section to README with a high-level architectural overview.

Q: Since the authors have disabled issue tracking on their github repositories, I urge them to add a contact method to sysbio-curie/hpcmaboss-artifact and sysbio-curie/MaBoSS.GPU, for users to obtain assistance and provide feedback, including bug reports.
A: This was a mistake, we now have enabled issue tracking on MaBoSS.GPU and hpcmaboss-artifact repositories. Thanks for reminding us. 

Q:  It is not clear whether the version provided via the colomoto conda repository is MPI enabled, so a clarification is needed.
A: This is something we have been considering, but we have not moved forward yet. We will most likely have to create specific conda packages which are MPI enabled, in addition to the classic ones. Same thing for MaBoSS.GPU. We also need to think about this for the colomoto docker, but again it might not be straightforward. For now, we think that the target users of these new implementations are knowledgeable enough to install them manually. 

Q: A concern is that the provided background is insufficient for the applicability and usefulness of the software to be apparent to the broader audience of BMC Bioinformatics. The authors should add more to provide context and insight into the interpretation and use of MaBoSS output, for those not already familiar with the previous MaBoSS versions.
A: We included a new section Statistics output and visualization.

Q: Finally, to improve accessibility, the following could do with explanation: variables “u” and “δt” in Algorithm 1, “PRAM”, “CNF”, “DNF”.
A: We explained the acronyms and provided comments for “δt” in the algorithm. “u” is to provide randomness in “δt” selection, which is now highlighted in the comment. Moreover, we reference the Gillespie algorithm, on which our algorithm is based.
